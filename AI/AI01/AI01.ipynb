{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI01.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twlX_dgeBkLs"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9BjHtbumz4V"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf A5-Courses/\n",
        "!git clone https://github.com/dimitrivinet/A5-Courses\n",
        "!mkdir -p A5-Courses/AI/AI01/output\n",
        "%cd A5-Courses/AI/AI01/src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7mglpei7MpG"
      },
      "source": [
        "!pip3 install efficientnet-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efAJ_TN3BgeX"
      },
      "source": [
        "Check torch, torchvision and CUDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBaSv4r0w38f"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU5ky4ADBqK0"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIH0LvRcBurI"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "\n",
        "import modules.models\n",
        "import modules.train\n",
        "from modules.data import PIL_to_tensor, CIFAR_transform, TrainingData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run9ctuIBv5a"
      },
      "source": [
        "N_CLASSES = 10\n",
        "DATASET_DIR = \"../dataset\"\n",
        "SAVE_PATH = \"../output\"\n",
        "NUM_EPOCHS = 100\n",
        "SAVE_ALL = False\n",
        "DEVICE = \"cuda:0\"\n",
        "# DEVICE=\"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4OJcrpgBxg-"
      },
      "source": [
        "# model = modules.models.MLP(N_CLASSES)\n",
        "# model = modules.models.LeNet5(N_CLASSES)\n",
        "# model = modules.models.VGG16(N_CLASSES)\n",
        "# model = modules.models.ResNet15(N_CLASSES)\n",
        "model = model = EfficientNet.from_pretrained('efficientnet-b1', num_classes=N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBGUFBqwB0es"
      },
      "source": [
        "trainset_MNIST = MNIST(\n",
        "    root=DATASET_DIR,\n",
        "    train=True,\n",
        "    transform=PIL_to_tensor,\n",
        "    target_transform=None,\n",
        "    download=True\n",
        ")\n",
        "validset_MNIST = MNIST(\n",
        "    root=DATASET_DIR,\n",
        "    train=False,\n",
        "    transform=PIL_to_tensor,\n",
        "    target_transform=None,\n",
        "    download=True\n",
        ")\n",
        "training_data_MNIST = TrainingData(trainset=trainset_MNIST,\n",
        "                                   validset=validset_MNIST,\n",
        "                                   trainloader=DataLoader(\n",
        "                                       trainset_MNIST,\n",
        "                                       batch_size=32,\n",
        "                                       shuffle=True,\n",
        "                                       num_workers=2,\n",
        "                                       pin_memory=True,\n",
        "                                   ),\n",
        "                                   validloader=DataLoader(\n",
        "                                       validset_MNIST,\n",
        "                                       batch_size=32,\n",
        "                                       shuffle=True,\n",
        "                                       num_workers=2,\n",
        "                                       pin_memory=True,\n",
        "                                   ))\n",
        "\n",
        "trainset_CIFAR = CIFAR10(\n",
        "    root=DATASET_DIR,\n",
        "    train=True,\n",
        "    transform=CIFAR_transform,\n",
        "    target_transform=None,\n",
        "    download=True\n",
        ")\n",
        "validset_CIFAR = CIFAR10(\n",
        "    root=DATASET_DIR,\n",
        "    train=False,\n",
        "    transform=CIFAR_transform,\n",
        "    target_transform=None,\n",
        "    download=True\n",
        ")\n",
        "training_data_CIFAR = TrainingData(trainset=trainset_CIFAR,\n",
        "                                    validset=validset_CIFAR,\n",
        "                                    trainloader=DataLoader(\n",
        "                                        trainset_CIFAR,\n",
        "                                        batch_size=32,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=2,\n",
        "                                        pin_memory=True,\n",
        "                                    ),\n",
        "                                    validloader=DataLoader(\n",
        "                                        validset_CIFAR,\n",
        "                                        batch_size=32,\n",
        "                                        shuffle=True,\n",
        "                                        num_workers=2,\n",
        "                                        pin_memory=True,\n",
        "                                    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSJkfvUbB4FB"
      },
      "source": [
        "modules.train.train(model=model,\n",
        "                    # training_data=training_data_MNIST,\n",
        "                    training_data=training_data_CIFAR,\n",
        "                    save_path=SAVE_PATH,\n",
        "                    num_epochs=NUM_EPOCHS,\n",
        "                    save_all=SAVE_ALL,\n",
        "                    device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Y_B7ueB8pP"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn76mNs3B-UL"
      },
      "source": [
        "Test layer output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdmR8euPBpZa"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "input = torch.randn(20, 128, 16, 16)\n",
        "\n",
        "# pool of square window of size=3, stride=2\n",
        "m = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "output = m(input)\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}